{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "chAgW1-N6g5n"
   },
   "source": [
    "# **LIVE DEMO**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HFt4KXDt6mdy"
   },
   "source": [
    "**Importing necessary LIbraries and making certain useful functions for automatic hand detection **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "DqrPwFJ84k1b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "model = load_model(\"model/incep_resnet_asl.h5\")\n",
    "\n",
    "def getcnthull(mask_img):\n",
    "    contours, hierarchy = cv.findContours(mask_img, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "    contours = max(contours, key=lambda x: cv.contourArea(x))\n",
    "    hull = cv.convexHull(contours)\n",
    "    return contours, hull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2-2U_dEI6N-V"
   },
   "source": [
    "**Created a Dictionary of Alphabets**\n",
    "\n",
    "Its required here becomes the predicting output is a number ranging from (0 to 29) each represents a character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Jz2H6hfe4k1m",
    "outputId": "abac47c1-1063-464d-ca07-1fa5ba3d92e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'A',\n",
       " 1: 'B',\n",
       " 2: 'C',\n",
       " 3: 'D',\n",
       " 4: 'E',\n",
       " 5: 'F',\n",
       " 6: 'G',\n",
       " 7: 'H',\n",
       " 8: 'I',\n",
       " 9: 'J',\n",
       " 10: 'K',\n",
       " 11: 'L',\n",
       " 12: 'M',\n",
       " 13: 'N',\n",
       " 14: 'O',\n",
       " 15: 'P',\n",
       " 16: 'Q',\n",
       " 17: 'R',\n",
       " 18: 'S',\n",
       " 19: 'T',\n",
       " 20: 'U',\n",
       " 21: 'V',\n",
       " 22: 'W',\n",
       " 23: 'X',\n",
       " 24: 'Y',\n",
       " 25: 'Z',\n",
       " 26: 'del',\n",
       " 27: 'Space',\n",
       " 28: 'Nothing'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "label_dict = {}\n",
    "for i in range(0, 26):\n",
    "    label_dict[i] = k[i]\n",
    "label_dict[26] = 'del'\n",
    "label_dict[27] = 'Space'\n",
    "label_dict[28] = 'Nothing'\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4kfc4aq64xUw"
   },
   "source": [
    "**Images were use for testing purpose**\n",
    "\n",
    "Few downloaded images from google were used, to test the model performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "CVPjlr8_4k1s"
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.1) /tmp/pip-req-build-7m_g9lbm/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-744c6d86bf34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sign_3.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhsvim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2HSV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlower\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m48\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mupper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mskinMask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minRange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhsvim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.1) /tmp/pip-req-build-7m_g9lbm/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "img = cv.imread(\"sign_3.jpg\")\n",
    "hsvim = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "lower = np.array([0, 48, 80])\n",
    "upper = np.array([20, 255, 255])\n",
    "skinMask = cv.inRange(hsvim, lower, upper)\n",
    "# skin = cv.bitwise_and(img, img, mask = skinMask)\n",
    "    \n",
    "    \n",
    "    \n",
    "blurred = cv.blur(skinMask, (2, 2))\n",
    "# cv.imshow(\"img\", skin)    \n",
    "    \n",
    "ret, thresh = cv.threshold(blurred, 0, 255, cv.THRESH_BINARY)\n",
    "\n",
    "contours, hull = getcnthull(thresh)\n",
    "cnt = contours\n",
    "\n",
    "x, y, w, h = cv.boundingRect(cnt)\n",
    "img = cv.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "cv.imshow(\"img\", img)\n",
    "# print(img.shape)\n",
    "\n",
    "\n",
    "hand_img = img[x-100:x+w+100, y-100:y+h+100]\n",
    "print(hand_img.shape)\n",
    "hand_img = cv.flip(hand_img, 1)\n",
    "resized = cv.resize(hand_img, (200, 200))\n",
    "normalized = resized / 255.0\n",
    "reshaped = np.reshape(normalized, (1, 200, 200, 3))\n",
    "        \n",
    "\n",
    "result = model.predict(reshaped)\n",
    "idx = np.argmax(result)\n",
    "# # print(result[0])\n",
    "print(label_dict[idx])\n",
    "# # img = cv.putText(img, label_dict[result[0]], (x+10, y+10),cv.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2)\n",
    "# cv.putText(img, label_dict[idx], (x+10, y-10),cv.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2)\n",
    "# cv.imshow(\"FInal\", img)\n",
    "        \n",
    "cv.waitKey()\n",
    "\n",
    "\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dwvYqowh5Jho"
   },
   "source": [
    "**Final Testing it on Video**\n",
    "\n",
    "For Live Video testing Run the code part below this\n",
    "\n",
    "Just Place your hand near the webcamera and make a sign.\n",
    "\n",
    "**Yay! Thats cool Right**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "pxhf47bP4k1u",
    "outputId": "41fa65ed-0813-432a-e7d5-6acc93b5198c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "H\n",
      "Y\n",
      "Y\n",
      "F\n",
      "Y\n",
      "F\n",
      "F\n",
      "F\n",
      "D\n",
      "F\n",
      "F\n",
      "F\n",
      "Space\n",
      "D\n",
      "F\n",
      "F\n",
      "F\n",
      "F\n",
      "F\n",
      "F\n",
      "F\n",
      "F\n",
      "F\n",
      "F\n",
      "Space\n",
      "F\n",
      "D\n",
      "D\n",
      "F\n",
      "del\n",
      "del\n",
      "del\n",
      "D\n",
      "D\n",
      "D\n",
      "D\n",
      "D\n",
      "D\n",
      "del\n",
      "del\n",
      "D\n",
      "D\n",
      "del\n",
      "del\n",
      "del\n",
      "del\n",
      "del\n",
      "D\n",
      "D\n",
      "del\n",
      "D\n",
      "D\n",
      "del\n",
      "D\n",
      "del\n",
      "D\n",
      "D\n",
      "D\n",
      "D\n",
      "D\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "I\n",
      "I\n",
      "B\n",
      "B\n",
      "B\n",
      "I\n",
      "D\n",
      "del\n",
      "Space\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "del\n",
      "del\n",
      "del\n",
      "del\n",
      "del\n",
      "del\n",
      "del\n",
      "del\n",
      "del\n",
      "del\n",
      "del\n",
      "del\n",
      "del\n",
      "del\n",
      "N\n",
      "N\n",
      "del\n",
      "N\n",
      "N\n",
      "N\n",
      "N\n",
      "D\n",
      "D\n",
      "del\n",
      "del\n",
      "del\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "V\n",
      "Space\n",
      "Space\n",
      "D\n",
      "Space\n",
      "Space\n",
      "V\n",
      "Space\n",
      "Space\n",
      "V\n",
      "V\n",
      "Q\n",
      "V\n",
      "D\n",
      "V\n",
      "del\n",
      "del\n",
      "del\n",
      "del\n",
      "del\n",
      "H\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "Space\n",
      "H\n",
      "B\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "B\n",
      "I\n",
      "I\n",
      "I\n",
      "H\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "H\n",
      "I\n",
      "B\n",
      "H\n",
      "H\n",
      "I\n",
      "G\n",
      "B\n",
      "N\n",
      "I\n",
      "I\n",
      "R\n",
      "Space\n",
      "H\n",
      "H\n",
      "Space\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "B\n",
      "I\n",
      "B\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "B\n",
      "I\n",
      "I\n",
      "I\n",
      "B\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "B\n",
      "I\n",
      "B\n",
      "I\n",
      "I\n",
      "B\n",
      "B\n",
      "B\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "D\n",
      "F\n",
      "F\n",
      "F\n",
      "A\n",
      "F\n",
      "F\n",
      "F\n",
      "F\n",
      "F\n",
      "F\n",
      "F\n",
      "F\n",
      "F\n",
      "F\n",
      "F\n",
      "F\n",
      "F\n",
      "F\n",
      "F\n",
      "F\n",
      "F\n",
      "F\n",
      "F\n",
      "F\n",
      "F\n",
      "F\n",
      "F\n",
      "F\n",
      "Y\n",
      "F\n",
      "F\n",
      "F\n",
      "Y\n",
      "Y\n",
      "Y\n",
      "Y\n",
      "Y\n",
      "Y\n",
      "Y\n",
      "F\n",
      "Y\n",
      "Y\n",
      "F\n",
      "Y\n",
      "F\n",
      "F\n",
      "F\n",
      "F\n",
      "F\n",
      "F\n",
      "F\n",
      "F\n",
      "F\n",
      "F\n",
      "Y\n",
      "D\n",
      "E\n",
      "F\n",
      "D\n",
      "D\n",
      "E\n",
      "E\n",
      "D\n",
      "E\n",
      "D\n",
      "D\n",
      "F\n",
      "F\n",
      "E\n",
      "F\n",
      "F\n",
      "E\n",
      "E\n",
      "F\n",
      "F\n",
      "F\n",
      "F\n",
      "F\n",
      "D\n",
      "D\n",
      "E\n",
      "Y\n",
      "D\n",
      "D\n",
      "D\n",
      "F\n",
      "D\n",
      "D\n",
      "A\n",
      "K\n",
      "D\n",
      "V\n",
      "D\n",
      "V\n",
      "V\n",
      "V\n",
      "D\n",
      "V\n",
      "V\n",
      "V\n",
      "V\n",
      "K\n",
      "V\n",
      "V\n",
      "V\n",
      "D\n",
      "V\n",
      "V\n",
      "V\n",
      "V\n",
      "V\n",
      "V\n",
      "V\n",
      "V\n",
      "K\n",
      "V\n",
      "K\n",
      "V\n",
      "V\n",
      "K\n",
      "V\n",
      "V\n",
      "H\n",
      "W\n",
      "V\n",
      "V\n",
      "V\n",
      "V\n",
      "V\n",
      "V\n",
      "V\n",
      "V\n",
      "V\n",
      "V\n",
      "V\n",
      "V\n",
      "V\n",
      "V\n",
      "V\n",
      "V\n",
      "V\n",
      "V\n",
      "V\n",
      "V\n",
      "V\n",
      "V\n",
      "V\n",
      "V\n",
      "K\n",
      "V\n",
      "V\n",
      "V\n",
      "V\n",
      "V\n",
      "K\n",
      "V\n",
      "V\n",
      "V\n",
      "V\n",
      "V\n",
      "V\n",
      "V\n",
      "V\n",
      "V\n",
      "V\n",
      "V\n",
      "V\n",
      "V\n",
      "V\n",
      "V\n",
      "V\n",
      "V\n",
      "V\n",
      "V\n",
      "V\n",
      "V\n",
      "V\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n",
      "I\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "IMAGE_SIZE = 200\n",
    "CROP_SIZE = 400\n",
    "\n",
    "\n",
    "classes = label_dict\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame.\n",
    "    ret, img = cap.read()\n",
    "    hsvim = cv.cvtColor(img, cv.COLOR_BGR2HSV)\n",
    "    lower = np.array([0, 48, 80])\n",
    "    upper = np.array([20, 255, 255])\n",
    "    skinMask = cv.inRange(hsvim, lower, upper)\n",
    "        \n",
    "    blurred = cv.blur(skinMask, (2, 2))\n",
    "\n",
    "    ret, thresh = cv.threshold(blurred, 0, 255, cv.THRESH_BINARY)\n",
    "\n",
    "    contours, hull = getcnthull(thresh)\n",
    "    cnt = contours\n",
    "\n",
    "    x, y, w, h = cv.boundingRect(cnt)\n",
    "    frame = cv.rectangle(img, (x-50, y-20), (x + w + 40, y + h + 10), (0, 255, 0), 2)\n",
    "    \n",
    "    \"\"\"Flipping might be required in some cases\"\"\"\n",
    "#     frame = cv2.flip(frame, 1)\n",
    "#     frame = cv2.flip(frame, 1)\n",
    "    \"\"\"Preprocessing the frame before input to the model\"\"\"\n",
    "    cropped = frame[0:CROP_SIZE, 0:CROP_SIZE]\n",
    "    resized_frame = cv2.resize(cropped, (200, 200))\n",
    "    reshaped_frame = (np.array(resized_frame)).reshape((1, 200, 200, 3))\n",
    "    frame_for_model = reshaped_frame/255\n",
    "\n",
    "    \"\"\"Prediction Time\"\"\"\n",
    "    prediction = np.array(model.predict(frame_for_model))\n",
    "    predicted_class = classes[prediction.argmax()]      # Selecting the max confidence index.\n",
    "    print(predicted_class)\n",
    "\n",
    "    cv2.putText(frame, predicted_class , (10, 450), 1, 2, (255, 255, 0), 2, cv2.LINE_AA)\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    # Press q to quit\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture.\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6gbnHw5J6HYg"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "prv3acLE4k1w"
   },
   "outputs": [],
   "source": [
    "cv.imshow(\"KK\",img)\n",
    "cv.waitKey(1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "detector_live.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
